# -*- coding: utf-8 -*-
import time
import random
import urllib.parse
from pathlib import Path
from datetime import datetime
from typing import List

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, StaleElementReferenceException

from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import pandas as pd
import re

# =============================
# –ù–ê–°–¢–†–û–ô–ö–ò
# =============================
SCROLL_PAUSE = 1.2
MAX_SCROLL_ERRORS = 5

OUTPUT_DIR = Path("yandex_result")
OUTPUT_DIR.mkdir(exist_ok=True)

# =============================
# –¢–†–ê–ù–°–õ–ò–¢–ï–†–ê–¶–ò–Ø
# =============================
TRANSLIT_MAP = {
    "–∞": "a", "–±": "b", "–≤": "v", "–≥": "g", "–¥": "d",
    "–µ": "e", "—ë": "e", "–∂": "zh", "–∑": "z", "–∏": "i",
    "–π": "y", "–∫": "k", "–ª": "l", "–º": "m", "–Ω": "n",
    "–æ": "o", "–ø": "p", "—Ä": "r", "—Å": "s", "—Ç": "t",
    "—É": "u", "—Ñ": "f", "—Ö": "h", "—Ü": "ts", "—á": "ch",
    "—à": "sh", "—â": "sch", "—ä": "", "—ã": "y", "—å": "",
    "—ç": "e", "—é": "yu", "—è": "ya"
}

def transliterate(text: str) -> str:
    return "".join(TRANSLIT_MAP.get(ch, ch) for ch in text.lower())

# =============================
# DRIVER
# =============================
def create_driver(headless=False) -> webdriver.Chrome:
    options = Options()
    if headless:
        options.add_argument("--headless=new")
    options.add_argument("--start-maximized")
    options.add_argument("--disable-blink-features=AutomationControlled")
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=options)

# =============================
# SCROLL + LINKS
# =============================
def collect_links(driver: webdriver.Chrome) -> List[str]:
    links = set()
    errors = 0

    try:
        slider = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "scroll__scrollbar-thumb"))
        )
    except TimeoutException:
        print("‚ùå scrollbar –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return []

    actions = ActionChains(driver)

    while errors < MAX_SCROLL_ERRORS:
        cards = driver.find_elements(By.CSS_SELECTOR, "a.link-overlay[href*='/org/']")
        new = 0

        for c in cards:
            try:
                href = c.get_attribute("href")
            except StaleElementReferenceException:
                continue

            if not href:
                continue

            clean = href.split("?")[0]
            if clean not in links:
                links.add(clean)
                new += 1

        errors = errors + 1 if new == 0 else 0

        try:
            actions.click_and_hold(slider).move_by_offset(0, 160).release().perform()
        except Exception:
            pass

        time.sleep(SCROLL_PAUSE + random.uniform(0, 0.4))

    return list(links)

# =============================
# –§–ò–õ–¨–¢–† –ü–û –ê–î–†–ï–°–£
# =============================
def address_matches(address: str, city: str) -> bool:
    return re.search(rf"\b{re.escape(city.lower())}\b", address.lower()) is not None

# =============================
# –ß–ê–°–´ –†–ê–ë–û–¢–´
# =============================
def parse_working_hours(soup: BeautifulSoup):
    status = soup.select_one("div.business-working-status-view")
    if status and "–∫—Ä—É–≥–ª–æ—Å—É—Ç–æ—á" in status.get_text(strip=True).lower():
        return "–ö—Ä—É–≥–ª–æ—Å—É—Ç–æ—á–Ω–æ"

    metas = soup.select("meta[itemprop='openingHours']")
    if not metas:
        return None

    entries = [m.get("content") for m in metas if m.get("content")]
    return normalize_hours(entries)

def normalize_hours(entries: List[str]) -> str | None:
    day_map = {
        "Mo": "–ü–Ω", "Tu": "–í—Ç", "We": "–°—Ä",
        "Th": "–ß—Ç", "Fr": "–ü—Ç", "Sa": "–°–±", "Su": "–í—Å"
    }

    parsed = []
    for e in entries:
        parts = e.split()
        if len(parts) == 2:
            day, hours = parts
            parsed.append((day_map.get(day, day), hours))

    if not parsed:
        return None

    hours_set = {h for _, h in parsed}
    if len(hours_set) == 1:
        return f"{parsed[0][0]}‚Äì{parsed[-1][0]} {parsed[0][1]}"

    return "; ".join(f"{d} {h}" for d, h in parsed)

# =============================
# PARSE CARDS
# =============================
def parse_cards(driver, links, city: str, category: str, filter_address: bool) -> List[dict]:
    rows = []

    for i, url in enumerate(links, 1):
        print(f"[{i}/{len(links)}] {url}")
        driver.get(url)
        time.sleep(2)

        soup = BeautifulSoup(driver.page_source, "lxml")

        name_el = soup.select_one("h1")
        addr_el = soup.select_one("div.business-contacts-view__address a")
        phone_el = soup.select_one("div.orgpage-phones-view__phone-number")
        site_el = soup.select_one("a.business-urls-view__link")

        address_text = addr_el.get_text(strip=True) if addr_el else None

        if filter_address and address_text and not address_matches(address_text, city):
            print(f"‚õî –ü—Ä–æ–ø—É—â–µ–Ω–æ: {address_text}")
            continue

        rows.append({
            "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": category,
            "–ù–∞—Å–µ–ª—ë–Ω–Ω—ã–π –ø—É–Ω–∫—Ç": city,
            "–ù–∞–∑–≤–∞–Ω–∏–µ": name_el.get_text(strip=True) if name_el else None,
            "–ê–¥—Ä–µ—Å": address_text,
            "–¢–µ–ª–µ—Ñ–æ–Ω": phone_el.get_text(strip=True) if phone_el else None,
            "–°–∞–π—Ç": site_el.get_text(strip=True) if site_el else None,
            "–ß–∞—Å—ã —Ä–∞–±–æ—Ç—ã": parse_working_hours(soup),
            "URL": url
        })

    return rows

# =============================
# MAIN
# =============================
def main():
    raw_categories = input("–í–≤–µ–¥–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é: ").strip()
    categories = [c.strip() for c in raw_categories.split(",") if c.strip()]

    raw_cities = input("–í–≤–µ–¥–∏—Ç–µ –≥–æ—Ä–æ–¥–∞ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é: ").strip()
    cities = [c.strip() for c in raw_cities.split(",") if c.strip()]


    filter_input = input("–í–∫–ª—é—á–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –Ω–∞—Å–µ–ª–µ–Ω–Ω–æ–º—É –ø—É–Ω–∫—Ç—É? (–î–∞/–ù–µ—Ç): ").strip().lower()
    filter_address = filter_input.startswith("–¥")  # –¥–∞/–î–∞/–î–ê ‚Üí True

    multiple = len(cities) > 1
    all_rows = []

    driver = create_driver(headless=False)

    try:
        for category in categories:
            for city in cities:
                print("===================================")
                print(f"üèô –ì–æ—Ä–æ–¥: {city} | üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}")

                query = f"{category} {city}"

                url = f"https://yandex.ru/maps/?text={urllib.parse.quote(query)}"
                driver.get(url)
                time.sleep(6)

                links = collect_links(driver)
                print(f"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {len(links)}")

                if links:
                    rows = parse_cards(driver, links, city, category, filter_address)
                    all_rows.extend(rows)
                else:
                    print("‚ö†Ô∏è –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

    finally:
        driver.quit()

    if not all_rows:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
        return

    date = datetime.now().strftime("%d.%m.%Y")

    # –§–æ—Ä–º–∞—Ç –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    if len(cities) == 1:
        filename = f"{transliterate(cities[0])}_{date}.xlsx"
    elif 2 <= len(cities) <= 3:
        prefix = "_".join(transliterate(c[:2]).capitalize() for c in cities)
        filename = f"{prefix}_{date}.xlsx"
    else:
        filename = f"Yandex_maps_result_{date}.xlsx"

    out = OUTPUT_DIR / filename
    pd.DataFrame(all_rows).to_excel(out, index=False)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(all_rows)} ‚Üí {out}")

if __name__ == "__main__":
    main()
